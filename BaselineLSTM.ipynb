{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPlFuJ4v3oOXl2jNvzjtVOC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ARVrFO-1oZVA"},"outputs":[],"source":["# Run once\n","\n","# !ssh-keygen -t rsa -b 4096 -f /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa -N \"\" -q\n","# !cat /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa.pub"]},{"cell_type":"code","source":["# Run everytime\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!mkdir -p ~/.ssh\n","!cp /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa ~/.ssh/\n","!cp /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa.pub ~/.ssh/\n","!chmod 600 ~/.ssh/id_rsa\n","!ssh-keyscan github.com >> ~/.ssh/known_hosts\n","\n","import os\n","\n","repo_dir = \"/content/ML_Project_2025\"\n","\n","if not os.path.exists(repo_dir):\n","  !git clone git@github.com:astroartics/ML_Project_2025.git {repo_dir}\n","else:\n","  %cd {repo_dir}\n","  !git pull\n","\n","%cd {repo_dir}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tjoHCPQpeeo","executionInfo":{"status":"ok","timestamp":1763146692726,"user_tz":-330,"elapsed":5404,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"a2fe31a6-0aed-4193-d401-6aa48d359363"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","# github.com:22 SSH-2.0-4b61ab4\n","# github.com:22 SSH-2.0-4b61ab4\n","# github.com:22 SSH-2.0-4b61ab4\n","# github.com:22 SSH-2.0-4b61ab4\n","# github.com:22 SSH-2.0-4b61ab4\n","Cloning into '/content/ML_Project_2025'...\n","remote: Enumerating objects: 149, done.\u001b[K\n","remote: Counting objects: 100% (149/149), done.\u001b[K\n","remote: Compressing objects: 100% (102/102), done.\u001b[K\n","remote: Total 149 (delta 77), reused 107 (delta 35), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (149/149), 1.56 MiB | 10.00 MiB/s, done.\n","Resolving deltas: 100% (77/77), done.\n","/content/ML_Project_2025\n"]}]},{"cell_type":"code","source":["# Run everytime\n","\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"\\nUsing device:\", device, \"\\n\")\n","\n","checkpoint_path = \"/content/drive/MyDrive/ML_Sem3_Project/preprocessed_data.pt\"\n","checkpoint = torch.load(\n","    checkpoint_path,\n","    map_location = device,  # ensures safe loading on CPU/GPU\n","    weights_only = False\n",")\n","\n","# --------------------------------\n","\n","# 4. Extract Variables\n","vocab = checkpoint[\"vocab\"]\n","inv_vocab = checkpoint[\"inv_vocab\"]\n","\n","# Move tensors to device\n","X_padded = checkpoint[\"X_padded\"].to(device)  # PyTorch does not run natively on TPU, hence using T4 GPU\n","y_tensor = checkpoint[\"y_tensor\"].to(device)\n","\n","# DataFrame cannot move to device; it stays on CPU\n","data = checkpoint[\"data\"]\n","\n","print(data[\"moves\"].head())\n","\n","# --------------------------------\n","\n","# 5. Status\n","print(\"\\nLoaded checkpoint successfully.\\n\")\n","print(\"X_padded shape:\", X_padded.shape)\n","print(\"y_tensor shape:\", y_tensor.shape)\n","print(\"Example vocab size:\", len(vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxgllwNtp2eh","executionInfo":{"status":"ok","timestamp":1763147760030,"user_tz":-330,"elapsed":17797,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"cf03a82a-2ae6-4c87-ca63-a743126530e8"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Using device: cpu \n","\n","0    e4 d5 Nf3 dxe4 Ne5 Nf6 d4 exd3 Bxd3 e6 Nc3 Bd6...\n","1    b4 e5 Bb2 d6 c3 Bf5 d3 Nf6 e4 Bg6 Be2 Be7 Nf3 ...\n","2    e4 d5 exd5 Qxd5 Nc3 Qa5 Nf3 Nf6 d4 Bg4 Bd2 Nc6...\n","3    e4 e5 Nf3 Nf6 Nc3 d6 Bc4 Be6 Qe2 Nbd7 d4 Bxc4 ...\n","4    d4 e6 c4 c6 Nc3 d5 cxd5 cxd5 e4 Nc6 e5 Qb6 Nge...\n","Name: moves, dtype: object\n","\n","Loaded checkpoint successfully.\n","\n","X_padded shape: torch.Size([658379, 292])\n","y_tensor shape: torch.Size([658379])\n","Example vocab size: 3672\n"]}]},{"cell_type":"code","source":["# Push changes to GitHub\n","\n","!cp /content/drive/MyDrive/ML_Sem3_Project/BaselineLSTM.ipynb /content/ML_Project_2025/\n","\n","!git add BaselineLSTM.ipynb\n","!git commit -m \"Added Notebook\"\n","!git push"],"metadata":{"id":"pwyNYaf7sT63","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763147556583,"user_tz":-330,"elapsed":1775,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"acfafd58-d844-4ee3-c2d2-0b20ea9af765"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[main d8fe549] Added Notebook\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n","Enumerating objects: 5, done.\n","Counting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 445 bytes | 445.00 KiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To github.com:astroartics/ML_Project_2025.git\n","   2e88ab1..d8fe549  main -> main\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qAjEDi-U1BOl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train/test split\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_padded,\n","    y_tensor,\n","    test_size = 0.2,  # 80-20 split\n","    random_state = 42,\n","    shuffle=True\n",")\n","\n","X_train.shape, X_test.shape\n"],"metadata":{"id":"Ihkax-6kw77K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763148364316,"user_tz":-330,"elapsed":7270,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"9532e032-ce1e-400e-8073-1410d0dedd2c"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([526703, 292]), torch.Size([131676, 292]))"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# PyTorch Datasets and DataLoaders\n","\n","# Why these are needed:\n","'''\n","1) Data cannot be fed to the model directly, because the number of integers is huge.\n","2) It must be given to the model in batches.\n","3) A DataLoader iterates over these batches.\n","4) DataLoader handles batching, shuffling, and feeding the model (if batch size = 64, the taking 64 sequences for X and 64 labels for y)\n","5) DataLoader also uses multiple workers to load batches faster.\n","6) Dataset allows Python to treat the data like a list (shuffling indices, slicing samples, fetching mini-batches automatically)\n","7) Dataset is a wrapper that tells PyTorch \"How to get the ith sample.\"\n","\n","8) Dataset: Defines how to access each sample\n","   DataLoader: Defines how to group examples into batches efficiently during training\n","'''\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","# X and y are not converted to a new format, they are just wrapped and become accessible through the Dataset interface\n","# For example, before Dataset, we manually index\n","# sample_X = X_train[100]\n","# sample_y = y_train[100]\n","# but, after Dataset, DataLoader can automatically fetch train_ds[100] -> returns (X_train[100], y_train[100])\n","class ChessDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    # Returns one sample to the DataLoader when requested: DataLoader needs data to be wrapped in a Dataset to\n","    # access it one by one randomly to form batches.\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","# DataLoaders\n","\n","batch_size = 64\n","\n","train_dataset = ChessDataset(X_train, y_train)\n","test_dataset  = ChessDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n","test_loader  = DataLoader(test_dataset, batch_size = batch_size)\n"],"metadata":{"id":"4I9UOiPA1Nc9"},"execution_count":null,"outputs":[]}]}