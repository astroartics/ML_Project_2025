{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPJTaNXHiCPs4KI61V8dK52"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ARVrFO-1oZVA"},"outputs":[],"source":["# Run once\n","\n","# !ssh-keygen -t rsa -b 4096 -f /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa -N \"\" -q\n","# !cat /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa.pub"]},{"cell_type":"code","source":["# Run everytime\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!mkdir -p ~/.ssh\n","!cp /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa ~/.ssh/\n","!cp /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa.pub ~/.ssh/\n","!chmod 600 ~/.ssh/id_rsa\n","!ssh-keyscan github.com >> ~/.ssh/known_hosts\n","\n","import os\n","\n","repo_dir = \"/content/ML_Project_2025\"\n","\n","if not os.path.exists(repo_dir):\n","  !git clone git@github.com:astroartics/ML_Project_2025.git {repo_dir}\n","else:\n","  %cd {repo_dir}\n","  !git pull\n","\n","%cd {repo_dir}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tjoHCPQpeeo","executionInfo":{"status":"ok","timestamp":1766134063695,"user_tz":-330,"elapsed":49246,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"d13d3322-bbf6-4c19-8606-bb9299880664"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","# github.com:22 SSH-2.0-aae3c6b\n","# github.com:22 SSH-2.0-aae3c6b\n","# github.com:22 SSH-2.0-aae3c6b\n","# github.com:22 SSH-2.0-aae3c6b\n","# github.com:22 SSH-2.0-aae3c6b\n","Cloning into '/content/ML_Project_2025'...\n","remote: Enumerating objects: 173, done.\u001b[K\n","remote: Counting objects: 100% (173/173), done.\u001b[K\n","remote: Compressing objects: 100% (118/118), done.\u001b[K\n","remote: Total 173 (delta 92), reused 124 (delta 43), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (173/173), 1.57 MiB | 1.41 MiB/s, done.\n","Resolving deltas: 100% (92/92), done.\n","/content/ML_Project_2025\n"]}]},{"cell_type":"code","source":["\n","# Run everytime\n","\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"\\nUsing device:\", device, \"\\n\")\n","\n","checkpoint_path = \"/content/drive/MyDrive/ML_Sem3_Project/preprocessed_data.pt\"\n","checkpoint = torch.load(\n","    checkpoint_path,\n","    map_location = device,  # ensures safe loading on CPU/GPU\n","    weights_only = False\n",")\n","\n","# --------------------------------\n","\n","# 4. Extract Variables\n","vocab = checkpoint[\"vocab\"]\n","inv_vocab = checkpoint[\"inv_vocab\"]\n","\n","# Move tensors to device\n","X_padded = checkpoint[\"X_padded\"].to(device)  # PyTorch does not run natively on TPU, hence using T4 GPU\n","y_tensor = checkpoint[\"y_tensor\"].to(device)\n","\n","# DataFrame cannot move to device; it stays on CPU\n","data = checkpoint[\"data\"]\n","\n","print(data[\"moves\"].head())\n","\n","# --------------------------------\n","\n","# 5. Status\n","print(\"\\nLoaded checkpoint successfully.\\n\")\n","print(\"X_padded shape:\", X_padded.shape)\n","print(\"y_tensor shape:\", y_tensor.shape)\n","print(\"Example vocab size:\", len(vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxgllwNtp2eh","executionInfo":{"status":"ok","timestamp":1766134173372,"user_tz":-330,"elapsed":29687,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"cfa30d49-ce56-46ab-ae64-01ad881f5a18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Using device: cuda \n","\n","0    e4 d5 Nf3 dxe4 Ne5 Nf6 d4 exd3 Bxd3 e6 Nc3 Bd6...\n","1    b4 e5 Bb2 d6 c3 Bf5 d3 Nf6 e4 Bg6 Be2 Be7 Nf3 ...\n","2    e4 d5 exd5 Qxd5 Nc3 Qa5 Nf3 Nf6 d4 Bg4 Bd2 Nc6...\n","3    e4 e5 Nf3 Nf6 Nc3 d6 Bc4 Be6 Qe2 Nbd7 d4 Bxc4 ...\n","4    d4 e6 c4 c6 Nc3 d5 cxd5 cxd5 e4 Nc6 e5 Qb6 Nge...\n","Name: moves, dtype: object\n","\n","Loaded checkpoint successfully.\n","\n","X_padded shape: torch.Size([658379, 292])\n","y_tensor shape: torch.Size([658379])\n","Example vocab size: 3672\n"]}]},{"cell_type":"code","source":["# Push changes to GitHub\n","\n","!git config --global user.email \"joshisanjanana114@gmail.com\"\n","!git config --global user.name \"Sanjana\"\n","\n","!cp /content/drive/MyDrive/ML_Sem3_Project/BaselineLSTM.ipynb /content/ML_Project_2025/\n","\n","!git add BaselineLSTM.ipynb\n","!git commit -m \"Added Notebook\"\n","!git push"],"metadata":{"id":"pwyNYaf7sT63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qAjEDi-U1BOl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train/test split\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_padded,\n","    y_tensor,\n","    test_size = 0.2,  # 80-20 split\n","    random_state = 42,\n","    shuffle=True\n",")\n","\n","X_train.shape, X_test.shape\n"],"metadata":{"id":"Ihkax-6kw77K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766134185041,"user_tz":-330,"elapsed":1969,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"ff3ccab4-deef-49ed-a9b1-2d616c189e24"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([526703, 292]), torch.Size([131676, 292]))"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# PyTorch Datasets and DataLoaders\n","\n","# Why these are needed:\n","'''\n","1) Data cannot be fed to the model directly, because the number of integers is huge.\n","2) It must be given to the model in batches.\n","3) A DataLoader iterates over these batches.\n","4) DataLoader handles batching, shuffling, and feeding the model (if batch size = 64, then taking 64 sequences for X and 64 labels for y)\n","5) DataLoader also uses multiple workers to load batches faster.\n","6) Dataset allows Python to treat the data like a list (shuffling indices, slicing samples, fetching mini-batches automatically)\n","7) Dataset is a wrapper that tells PyTorch \"How to get the ith sample.\"\n","8) Dataset: Defines how to access each sample\n","   DataLoader: Defines how to group examples into batches efficiently during training\n","'''\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","# X and y are not converted to a new format, they are just wrapped and become accessible through the Dataset interface\n","# For example, before Dataset, we manually index\n","# sample_X = X_train[100]\n","# sample_y = y_train[100]\n","# but, after Dataset, DataLoader can automatically fetch train_ds[100] -> returns (X_train[100], y_train[100])\n","class ChessDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    # Returns one sample to the DataLoader when requested: DataLoader needs data to be wrapped in a Dataset to\n","    # access it one by one randomly to form batches.\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","# DataLoaders\n","\n","batch_size = 64\n","\n","train_dataset = ChessDataset(X_train, y_train)\n","test_dataset  = ChessDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n","test_loader  = DataLoader(test_dataset, batch_size = batch_size)\n"],"metadata":{"id":"4I9UOiPA1Nc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"G0FplOMM25dZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LSTM\n","\n","import torch\n","import torch.nn as nn\n","\n","# Defining the Baseline LSTM model\n","# Training time for 5 epochs using a GPU: ~15 minutes\n","\n","class BaselineLSTM(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_layers=1, padding_idx=0):\n","        super().__init__()\n","        # Embedding: converts token IDs -> dense vectors\n","        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim, padding_idx=padding_idx)\n","        # LSTM: processes sequence of embeddings\n","        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n","        # Final linear layer to produce logits for each vocabulary token\n","        self.fc = nn.Linear(hidden_dim, vocab_size)\n","\n","    def forward(self, x):\n","        # x: LongTensor of shape (batch_size, seq_len)\n","        emb = self.embedding(x)                     # -> (batch_size, seq_len, embed_dim)\n","        outputs, (h_n, c_n) = self.lstm(emb)        # outputs -> (batch_size, seq_len, hidden_dim)\n","                                                   # h_n -> (num_layers, batch_size, hidden_dim)\n","        last_hidden = outputs[:, -1, :]             # take output at last time-step -> (batch_size, hidden_dim)\n","        logits = self.fc(last_hidden)               # -> (batch_size, vocab_size)\n","        return logits\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","vocab_size = len(vocab)        # vocab from your preprocessing (includes PAD and UNK)\n","model = BaselineLSTM(vocab_size=vocab_size, embed_dim=128, hidden_dim=256, num_layers=1, padding_idx=vocab['<PAD>']).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss(ignore_index=vocab['<PAD>'])   # ignore pad index if used in targets (usually not)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","# Training loop\n","num_epochs = 5\n","lstm_train_losses = []\n","\n","model.train()\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    for X_batch, y_batch in train_loader:\n","        # Move to device\n","        X_batch = X_batch.to(device)                   # (batch_size, seq_len), dtype=torch.long\n","        y_batch = y_batch.to(device)                   # (batch_size,), dtype=torch.long (class indices)\n","\n","        optimizer.zero_grad()\n","\n","        logits = model(X_batch)                        # (batch_size, vocab_size)\n","        loss = criterion(logits, y_batch)              # CrossEntropy expects (N, C) and targets (N,)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * X_batch.size(0)    # sum-of-losses for averaging later\n","\n","    avg_loss = total_loss / len(train_loader.dataset)\n","    lstm_train_losses.append(avg_loss)\n","    print(f\"Epoch {epoch+1}/{num_epochs}  Train loss: {avg_loss:.4f}\")\n","\n","# Predicting / decoding one example\n","model.eval()\n","with torch.no_grad():\n","    sample_X = X_test[0].unsqueeze(0).to(device)      # shape (1, seq_len)\n","    logits = model(sample_X)                          # (1, vocab_size)\n","    pred_id = logits.argmax(dim=-1).item()            # integer token id\n","    pred_move = inv_vocab[pred_id]                    # decode to SAN using your inv_vocab\n","    print(\"Predicted token id:\", pred_id, \"Predicted SAN:\", pred_move)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C66lA_5N2QoL","outputId":"16a5fc13-3f3d-4157-e83e-7ac32e616804"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5  Train loss: 6.3863\n","Epoch 2/5  Train loss: 6.3628\n","Epoch 3/5  Train loss: 6.3591\n","Epoch 4/5  Train loss: 6.3574\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NrCu2ru9HUPV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transformer\n","# Training time for 5 epochs using a GPU: ~30 minutes\n","\n","import math\n","import torch\n","import torch.nn as nn\n","\n","# Since trandformers have no notion of order, we must add positional encoding information\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super().__init__()\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len).unsqueeze(1)\n","        div_term = torch.exp(\n","            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n","        )\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n","        self.register_buffer(\"pe\", pe)\n","\n","    def forward(self, x):\n","        # x: (batch_size, seq_len, d_model)\n","        return x + self.pe[:, :x.size(1)]\n","\n","class TransformerBaseline(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size,\n","        d_model=128,\n","        nhead=4,\n","        num_layers=2,\n","        dim_feedforward=512,\n","        dropout=0.1,\n","        padding_idx=0,\n","        max_len=5000\n","    ):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=d_model,\n","            padding_idx=padding_idx\n","        )\n","\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=nhead,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout,\n","            batch_first=True   # IMPORTANT: matches your (B, T, D)\n","        )\n","\n","        self.transformer_encoder = nn.TransformerEncoder(\n","            encoder_layer,\n","            num_layers=num_layers\n","        )\n","\n","        self.fc = nn.Linear(d_model, vocab_size)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x: (batch_size, seq_len)\n","        \"\"\"\n","\n","        # Padding mask: True where PAD\n","        padding_mask = (x == vocab['<PAD>'])\n","\n","        emb = self.embedding(x)                    # (B, T, D)\n","        emb = self.positional_encoding(emb)        # (B, T, D)\n","\n","        out = self.transformer_encoder(\n","            emb,\n","            src_key_padding_mask=padding_mask\n","        )                                           # (B, T, D)\n","\n","        # Take last non-pad token representation\n","        lengths = (~padding_mask).sum(dim=1) - 1   # (B,)\n","        last_hidden = out[torch.arange(out.size(0)), lengths]\n","\n","        logits = self.fc(last_hidden)               # (B, vocab_size)\n","        return logits\n","\n","# Instantiating model, loss, optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = TransformerBaseline(\n","    vocab_size=len(vocab),\n","    d_model=128,\n","    nhead=4,\n","    num_layers=2,\n","    dim_feedforward=512,\n","    padding_idx=vocab['<PAD>']\n",").to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Training loop (Same as LSTM)\n","num_epochs = 5\n","transformer_train_losses = []\n","\n","model.train()\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","\n","    for X_batch, y_batch in train_loader:\n","        X_batch = X_batch.to(device)\n","        y_batch = y_batch.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        logits = model(X_batch)\n","        loss = criterion(logits, y_batch)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * X_batch.size(0)\n","\n","    avg_loss = total_loss / len(train_loader.dataset)\n","    transformer_train_losses.append(avg_loss)\n","    print(f\"Epoch {epoch+1}/{num_epochs}  Train loss: {avg_loss:.4f}\")\n","\n","# Predicting the next move\n","model.eval()\n","with torch.no_grad():\n","    sample_X = X_test[0].unsqueeze(0).to(device)\n","    logits = model(sample_X)\n","    pred_id = logits.argmax(dim=-1).item()\n","    pred_move = inv_vocab[pred_id]\n","\n","    print(\"Predicted move:\", pred_move)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95h0c5B22iwl","executionInfo":{"status":"ok","timestamp":1766137662326,"user_tz":-330,"elapsed":1777857,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"24487b29-aad2-4bec-b1c2-69a72d5f82db"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5  Train loss: 5.8599\n","Epoch 2/5  Train loss: 5.3223\n","Epoch 3/5  Train loss: 5.0798\n","Epoch 4/5  Train loss: 4.9201\n","Epoch 5/5  Train loss: 4.8062\n","Predicted move: Nc3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n","  output = torch._nested_tensor_from_mask(\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(lstm_train_losses, label=\"LSTM\")\n","plt.plot(transformer_train_losses, label=\"Transformer\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Cross-Entropy Loss\")\n","plt.legend()\n","plt.title(\"Training Loss Comparison\")\n","plt.show()"],"metadata":{"id":"ewrFE1xQ3SBN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BGcKJH09-1wN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install python-chess pygame"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HsnDs914-2ma","executionInfo":{"status":"ok","timestamp":1766137674801,"user_tz":-330,"elapsed":8894,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"c51fa12d-a37e-4b73-f693-fd3241fdb769"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-chess\n","  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\n","Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (2.6.1)\n","Collecting chess<2,>=1 (from python-chess)\n","  Downloading chess-1.11.2.tar.gz (6.1 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m224.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n","Building wheels for collected packages: chess\n","  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=74f3161223d9aa9a19082d735c96db1c6814d8226f744a3d300f8bbe1c262d43\n","  Stored in directory: /root/.cache/pip/wheels/83/1f/4e/8f4300f7dd554eb8de70ddfed96e94d3d030ace10c5b53d447\n","Successfully built chess\n","Installing collected packages: chess, python-chess\n","Successfully installed chess-1.11.2 python-chess-1.999\n"]}]},{"cell_type":"code","source":["# Chess game GUI\n","\n","import chess\n","import chess.svg\n","from IPython.display import SVG, display\n","\n","def show_board(board):\n","    display(SVG(chess.svg.board(board=board)))\n","\n","def encode_move_sequence(move_list, vocab, max_len):\n","    ids = [vocab.get(m, vocab['<UNK>']) for m in move_list]\n","    ids = ids[-max_len:]\n","    ids = [vocab['<PAD>']] * (max_len - len(ids)) + ids\n","    return torch.tensor(ids, dtype=torch.long)\n","\n","board = chess.Board()\n","moves = [\"e4\", \"e5\", \"Nf3\", \"Nc6\"]\n","\n","for san in moves:\n","    board.push_san(san)\n","\n","show_board(board)\n","\n","pred_move = predict_next_move(transformer_model, moves)\n","print(\"Transformer predicts:\", pred_move)\n","\n","try:\n","    board.push_san(pred_move)\n","    show_board(board)\n","except:\n","    print(\"Illegal move predicted\")\n"],"metadata":{"id":"m95SnJ76-8fj"},"execution_count":null,"outputs":[]}]}