{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOXRvP3R99keqxveR44IsDb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ARVrFO-1oZVA","executionInfo":{"status":"ok","timestamp":1766394306308,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}}},"outputs":[],"source":["# Run once\n","\n","# !ssh-keygen -t rsa -b 4096 -f /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa -N \"\" -q\n","# !cat /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa.pub"]},{"cell_type":"code","source":["# Run everytime\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!mkdir -p ~/.ssh\n","!cp /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa ~/.ssh/\n","!cp /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa.pub ~/.ssh/\n","!chmod 600 ~/.ssh/id_rsa\n","!ssh-keyscan github.com >> ~/.ssh/known_hosts\n","\n","import os\n","\n","repo_dir = \"/content/ML_Project_2025\"\n","\n","if not os.path.exists(repo_dir):\n","  !git clone git@github.com:astroartics/ML_Project_2025.git {repo_dir}\n","else:\n","  %cd {repo_dir}\n","  !git pull\n","\n","%cd {repo_dir}"],"metadata":{"id":"-tjoHCPQpeeo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Run everytime\n","\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"\\nUsing device:\", device, \"\\n\")\n","\n","checkpoint_path = \"/content/drive/MyDrive/ML_Sem3_Project/preprocessed_data.pt\"\n","checkpoint = torch.load(\n","    checkpoint_path,\n","    map_location = device,  # ensures safe loading on CPU/GPU\n","    weights_only = False\n",")\n","\n","# --------------------------------\n","\n","# 4. Extract Variables\n","vocab = checkpoint[\"vocab\"]\n","inv_vocab = checkpoint[\"inv_vocab\"]\n","\n","# Move tensors to device\n","X_padded = checkpoint[\"X_padded\"].to(device)  # PyTorch does not run natively on TPU, hence using T4 GPU\n","y_tensor = checkpoint[\"y_tensor\"].to(device)\n","\n","# DataFrame cannot move to device; it stays on CPU\n","data = checkpoint[\"data\"]\n","\n","print(data[\"moves\"].head())\n","\n","# --------------------------------\n","\n","# 5. Status\n","print(\"\\nLoaded checkpoint successfully.\\n\")\n","print(\"X_padded shape:\", X_padded.shape)\n","print(\"y_tensor shape:\", y_tensor.shape)\n","print(\"Example vocab size:\", len(vocab))"],"metadata":{"id":"wxgllwNtp2eh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Push changes to GitHub\n","\n","!git config --global user.email \"joshisanjanana114@gmail.com\"\n","!git config --global user.name \"Sanjana\"\n","\n","!cp /content/drive/MyDrive/ML_Sem3_Project/BaselineLSTM.ipynb /content/ML_Project_2025/\n","\n","!git add BaselineLSTM.ipynb\n","!git commit -m \"Added Notebook\"\n","!git push"],"metadata":{"id":"pwyNYaf7sT63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qAjEDi-U1BOl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train/test split\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_padded,\n","    y_tensor,\n","    test_size = 0.2,  # 80-20 split\n","    random_state = 42,\n","    shuffle=True\n",")\n","\n","X_train.shape, X_test.shape\n"],"metadata":{"id":"Ihkax-6kw77K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PyTorch Datasets and DataLoaders\n","\n","# Why these are needed:\n","'''\n","1) Data cannot be fed to the model directly, because the number of integers is huge.\n","2) It must be given to the model in batches.\n","3) A DataLoader iterates over these batches.\n","4) DataLoader handles batching, shuffling, and feeding the model (if batch size = 64, then taking 64 sequences for X and 64 labels for y)\n","5) DataLoader also uses multiple workers to load batches faster.\n","6) Dataset allows Python to treat the data like a list (shuffling indices, slicing samples, fetching mini-batches automatically)\n","7) Dataset is a wrapper that tells PyTorch \"How to get the ith sample.\"\n","8) Dataset: Defines how to access each sample\n","   DataLoader: Defines how to group examples into batches efficiently during training\n","'''\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","# X and y are not converted to a new format, they are just wrapped and become accessible through the Dataset interface\n","# For example, before Dataset, we manually index\n","# sample_X = X_train[100]\n","# sample_y = y_train[100]\n","# but, after Dataset, DataLoader can automatically fetch train_ds[100] -> returns (X_train[100], y_train[100])\n","class ChessDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    # Returns one sample to the DataLoader when requested: DataLoader needs data to be wrapped in a Dataset to\n","    # access it one by one randomly to form batches.\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","# DataLoaders\n","\n","batch_size = 64\n","\n","train_dataset = ChessDataset(X_train, y_train)\n","test_dataset  = ChessDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n","test_loader  = DataLoader(test_dataset, batch_size = batch_size)\n"],"metadata":{"id":"4I9UOiPA1Nc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"G0FplOMM25dZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LSTM\n","\n","import torch\n","import torch.nn as nn\n","\n","# Defining the Baseline LSTM model\n","# Training time for 5 epochs using a GPU: ~15 minutes\n","\n","class BaselineLSTM(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_layers=1, padding_idx=0):\n","        super().__init__()\n","        # Embedding: converts token IDs -> dense vectors\n","        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim, padding_idx=padding_idx)\n","        # LSTM: processes sequence of embeddings\n","        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n","        # Final linear layer to produce logits for each vocabulary token\n","        self.fc = nn.Linear(hidden_dim, vocab_size)\n","\n","    def forward(self, x):\n","        # x: LongTensor of shape (batch_size, seq_len)\n","        emb = self.embedding(x)                     # -> (batch_size, seq_len, embed_dim)\n","        outputs, (h_n, c_n) = self.lstm(emb)        # outputs -> (batch_size, seq_len, hidden_dim)\n","                                                   # h_n -> (num_layers, batch_size, hidden_dim)\n","        last_hidden = outputs[:, -1, :]             # take output at last time-step -> (batch_size, hidden_dim)\n","        logits = self.fc(last_hidden)               # -> (batch_size, vocab_size)\n","        return logits\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","vocab_size = len(vocab)        # vocab from your preprocessing (includes PAD and UNK)\n","lstm_model = BaselineLSTM(vocab_size=vocab_size, embed_dim=128, hidden_dim=256, num_layers=1, padding_idx=vocab['<PAD>']).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss(ignore_index=vocab['<PAD>'])   # ignore pad index if used in targets (usually not)\n","optimizer = torch.optim.Adam(lstm_model.parameters(), lr=1e-3)\n","\n","# Training loop\n","num_epochs = 5\n","lstm_train_losses = []\n","\n","lstm_model.train()\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    for X_batch, y_batch in train_loader:\n","        # Move to device\n","        X_batch = X_batch.to(device)                   # (batch_size, seq_len), dtype=torch.long\n","        y_batch = y_batch.to(device)                   # (batch_size,), dtype=torch.long (class indices)\n","\n","        optimizer.zero_grad()\n","\n","        logits = lstm_model(X_batch)                        # (batch_size, vocab_size)\n","        loss = criterion(logits, y_batch)              # CrossEntropy expects (N, C) and targets (N,)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * X_batch.size(0)    # sum-of-losses for averaging later\n","\n","    avg_loss = total_loss / len(train_loader.dataset)\n","    lstm_train_losses.append(avg_loss)\n","    print(f\"Epoch {epoch+1}/{num_epochs}  Train loss: {avg_loss:.4f}\")\n","\n","# Predicting / decoding one example\n","lstm_model.eval()\n","with torch.no_grad():\n","    sample_X = X_test[0].unsqueeze(0).to(device)      # shape (1, seq_len)\n","    logits = lstm_model(sample_X)                          # (1, vocab_size)\n","    pred_id = logits.argmax(dim=-1).item()            # integer token id\n","    pred_move = inv_vocab[pred_id]                    # decode to SAN using your inv_vocab\n","    print(\"Predicted token id:\", pred_id, \"Predicted SAN:\", pred_move)\n"],"metadata":{"id":"C66lA_5N2QoL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NrCu2ru9HUPV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transformer\n","# Training time for 5 epochs using a GPU: ~30 minutes\n","\n","import math\n","import torch\n","import torch.nn as nn\n","\n","# Since trandformers have no notion of order, we must add positional encoding information\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super().__init__()\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len).unsqueeze(1)\n","        div_term = torch.exp(\n","            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n","        )\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n","        self.register_buffer(\"pe\", pe)\n","\n","    def forward(self, x):\n","        # x: (batch_size, seq_len, d_model)\n","        return x + self.pe[:, :x.size(1)]\n","\n","class TransformerBaseline(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size,\n","        d_model=128,\n","        nhead=4,\n","        num_layers=2,\n","        dim_feedforward=512,\n","        dropout=0.1,\n","        padding_idx=0,\n","        max_len=5000\n","    ):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=d_model,\n","            padding_idx=padding_idx\n","        )\n","\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=nhead,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout,\n","            batch_first=True   # IMPORTANT: matches your (B, T, D)\n","        )\n","\n","        self.transformer_encoder = nn.TransformerEncoder(\n","            encoder_layer,\n","            num_layers=num_layers\n","        )\n","\n","        self.fc = nn.Linear(d_model, vocab_size)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x: (batch_size, seq_len)\n","        \"\"\"\n","\n","        # Padding mask: True where PAD\n","        padding_mask = (x == vocab['<PAD>'])\n","\n","        emb = self.embedding(x)                    # (B, T, D)\n","        emb = self.positional_encoding(emb)        # (B, T, D)\n","\n","        out = self.transformer_encoder(\n","            emb,\n","            src_key_padding_mask=padding_mask\n","        )                                           # (B, T, D)\n","\n","        # Take last non-pad token representation\n","        lengths = (~padding_mask).sum(dim=1) - 1   # (B,)\n","        last_hidden = out[torch.arange(out.size(0)), lengths]\n","\n","        logits = self.fc(last_hidden)               # (B, vocab_size)\n","        return logits\n","\n","# Instantiating model, loss, optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","transformer_model = TransformerBaseline(\n","    vocab_size=len(vocab),\n","    d_model=128,\n","    nhead=4,\n","    num_layers=2,\n","    dim_feedforward=512,\n","    padding_idx=vocab['<PAD>']\n",").to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(transformer_model.parameters(), lr=1e-4)\n","\n","# Training loop (Same as LSTM)\n","num_epochs = 5\n","transformer_train_losses = []\n","\n","transformer_model.train()\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","\n","    for X_batch, y_batch in train_loader:\n","        X_batch = X_batch.to(device)\n","        y_batch = y_batch.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        logits = transformer_model(X_batch)\n","        loss = criterion(logits, y_batch)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * X_batch.size(0)\n","\n","    avg_loss = total_loss / len(train_loader.dataset)\n","    transformer_train_losses.append(avg_loss)\n","    print(f\"Epoch {epoch+1}/{num_epochs}  Train loss: {avg_loss:.4f}\")\n","\n","# Predicting the next move\n","transformer_model.eval()\n","with torch.no_grad():\n","    sample_X = X_test[0].unsqueeze(0).to(device)\n","    logits = transformer_model(sample_X)\n","    pred_id = logits.argmax(dim=-1).item()\n","    pred_move = inv_vocab[pred_id]\n","\n","    print(\"Predicted move:\", pred_move)"],"metadata":{"id":"95h0c5B22iwl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(7, 11))\n","\n","plt.subplot(2, 1, 1)\n","plt.plot(lstm_train_losses, label=\"LSTM\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Cross-Entropy Loss\")\n","plt.title(\"Training Loss: LSTM\")\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(transformer_train_losses, label=\"Transformer\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Cross-Entropy Loss\")\n","plt.title(\"Training Loss: Transformer\")\n","\n","plt.show()"],"metadata":{"id":"ewrFE1xQ3SBN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install python-chess"],"metadata":{"id":"BGcKJH09-1wN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import chess\n","import chess.pgn\n","import urllib.parse\n","import webbrowser\n","from IPython.display import HTML, display\n","\n","board = chess.Board()\n","game = chess.pgn.Game()\n","node = game\n","idx = 0  # First test example\n","\n","def decode_sequence(x_tensor, inv_vocab, pad_id=0):\n","    # x_tensor: shape (seq_len,)\n","    moves = []\n","    for token_id in x_tensor.tolist():\n","        if token_id == pad_id:\n","            break\n","        moves.append(inv_vocab[token_id])\n","    return moves\n","\n","san_moves = decode_sequence(X_test[idx], inv_vocab)\n","\n","for san in san_moves:\n","    move = board.parse_san(san)\n","    board.push(move)\n","    node = node.add_variation(move)\n","\n","# Now add predicted move\n","predicted_move = board.parse_san(pred_move)\n","board.push(predicted_move)\n","node.add_variation(predicted_move)\n","\n","print(game[0])\n","\n","pgn_str = str(game)\n","url = \"https://lichess.org/analysis/pgn/\" + urllib.parse.quote(pgn_str)\n","# print(url)\n","\n","display(HTML(f'<a href=\"{url}\" target=\"_blank\">Open Lichess Analysis</a>'))"],"metadata":{"id":"R1GRM7o_dc95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HsnDs914-2ma"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Chess game GUI (SVG)\n","\n","import chess\n","import chess.svg\n","from IPython.display import SVG, display\n","\n","def show_board(board, size=300):\n","    display(SVG(chess.svg.board(board=board, size=size)))\n","\n","def predict_next_move(model, move_sequence, vocab, inv_vocab, device, top_k=1):\n","    \"\"\"\n","    model        : trained LSTM or Transformer\n","    move_sequence: list of SAN moves, e.g. [\"e4\", \"e5\", \"Nf3\"]\n","    \"\"\"\n","\n","    model.eval()\n","\n","    # Convert SAN moves â†’ token IDs\n","    input_ids = [vocab.get(m, vocab['<UNK>']) for m in move_sequence]\n","\n","    # Shape: (1, seq_len)\n","    x = torch.tensor(input_ids).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        logits = model(x)              # (1, vocab_size)\n","        probs = torch.softmax(logits, dim=-1)\n","\n","        if top_k == 1:\n","            pred_id = probs.argmax(dim=-1).item()\n","            return inv_vocab[pred_id]\n","\n","        else:\n","            topk_ids = torch.topk(probs, top_k).indices.squeeze(0).tolist()\n","            return [inv_vocab[i] for i in topk_ids]\n","\n","\n","def encode_move_sequence(move_list, vocab, max_len):\n","    ids = [vocab.get(m, vocab['<UNK>']) for m in move_list]\n","    ids = ids[-max_len:]\n","    ids = [vocab['<PAD>']] * (max_len - len(ids)) + ids\n","    return torch.tensor(ids, dtype=torch.long)\n","\n","board = chess.Board()\n","moves = [\"e4\", \"e5\", \"Nf3\", \"Nc6\"]\n","sequence_san = [\n","    inv_vocab[t.item()]\n","    for t in X_test[0]\n","    if t.item() != vocab['<PAD>']\n","]\n","sequence_san_y = [\n","    inv_vocab[t.item()]\n","    for t in y_test\n","    if t.item() != vocab['<PAD>']\n","]\n","print(\"Expected move: \", sequence_san_y[0])\n","\n","for san in sequence_san:\n","    board.push_san(san)\n","\n","show_board(board)\n","\n","pred_move = predict_next_move(transformer_model, sequence_san, vocab, inv_vocab, device)\n","print(\"Transformer predicts:\", pred_move)\n","\n","try:\n","    board.push_san(pred_move)\n","    show_board(board)\n","except:\n","    print(\"Illegal move predicted\")"],"metadata":{"id":"m95SnJ76-8fj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fen = board.fen()\n","# print(fen)\n","\n","# import webbrowser\n","\n","# url = f\"https://lichess.org/analysis/{fen.replace(' ', '_')}\"\n","# webbrowser.open(url)\n","\n","# def decode_sequence(x_tensor, inv_vocab, pad_id=0):\n","#     # x_tensor: shape (seq_len,)\n","#     moves = []\n","#     for token_id in x_tensor.tolist():\n","#         if token_id == pad_id:\n","#             break\n","#         moves.append(inv_vocab[token_id])\n","#     return moves\n","\n","# idx = 0  # take first test example\n","# san_moves = decode_sequence(X_test[idx], inv_vocab)\n","# print(san_moves)\n","\n","# def san_list_to_pgn(san_moves):\n","#     pgn = []\n","#     move_num = 1\n","#     for i in range(0, len(san_moves), 2):\n","#         if i + 1 < len(san_moves):\n","#             pgn.append(f\"{move_num}. {san_moves[i]} {san_moves[i+1]}\")\n","#         else:\n","#             pgn.append(f\"{move_num}. {san_moves[i]}\")\n","#         move_num += 1\n","#     return \" \".join(pgn)\n","\n","# pgn_moves = san_list_to_pgn(san_moves)\n","# print(pgn_moves)\n","\n","# import urllib.parse\n","\n","# encoded_pgn = urllib.parse.quote(pgn_moves)\n","# url = f\"https://lichess.org/analysis/pgn/{encoded_pgn}\"\n","# webbrowser.open(url)\n","\n","# from IPython.display import HTML, display\n","\n","# display(HTML(f'<a href=\"{url}\" target=\"_blank\">Open Lichess Analysis</a>'))"],"metadata":{"id":"nlmzI_v2WWSa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Dokf7QNUcJ9J"},"execution_count":null,"outputs":[]}]}