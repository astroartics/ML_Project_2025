{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnT9w4Q4gJjQP3/Dex/xtm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":24,"metadata":{"id":"ARVrFO-1oZVA","executionInfo":{"status":"ok","timestamp":1763147312748,"user_tz":-330,"elapsed":2,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}}},"outputs":[],"source":["# Run once\n","\n","# !ssh-keygen -t rsa -b 4096 -f /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa -N \"\" -q\n","# !cat /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa.pub"]},{"cell_type":"code","source":["# Run everytime\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!mkdir -p ~/.ssh\n","!cp /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa ~/.ssh/\n","!cp /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa.pub ~/.ssh/\n","!chmod 600 ~/.ssh/id_rsa\n","!ssh-keyscan github.com >> ~/.ssh/known_hosts\n","\n","import os\n","\n","repo_dir = \"/content/ML_Project_2025\"\n","\n","if not os.path.exists(repo_dir):\n","  !git clone git@github.com:astroartics/ML_Project_2025.git {repo_dir}\n","else:\n","  %cd {repo_dir}\n","  !git pull\n","\n","%cd {repo_dir}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tjoHCPQpeeo","executionInfo":{"status":"ok","timestamp":1763146692726,"user_tz":-330,"elapsed":5404,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"a2fe31a6-0aed-4193-d401-6aa48d359363"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","# github.com:22 SSH-2.0-4b61ab4\n","# github.com:22 SSH-2.0-4b61ab4\n","# github.com:22 SSH-2.0-4b61ab4\n","# github.com:22 SSH-2.0-4b61ab4\n","# github.com:22 SSH-2.0-4b61ab4\n","Cloning into '/content/ML_Project_2025'...\n","remote: Enumerating objects: 149, done.\u001b[K\n","remote: Counting objects: 100% (149/149), done.\u001b[K\n","remote: Compressing objects: 100% (102/102), done.\u001b[K\n","remote: Total 149 (delta 77), reused 107 (delta 35), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (149/149), 1.56 MiB | 10.00 MiB/s, done.\n","Resolving deltas: 100% (77/77), done.\n","/content/ML_Project_2025\n"]}]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"\\nUsing device:\", device, \"\\n\")\n","\n","checkpoint_path = \"/content/drive/MyDrive/ML_Sem3_Project/preprocessed_data.pt\"\n","checkpoint = torch.load(\n","    checkpoint_path,\n","    map_location = device,  # ensures safe loading on CPU/GPU\n","    weights_only = False\n",")\n","\n","# --------------------------------\n","\n","# 4. Extract Variables\n","vocab = checkpoint[\"vocab\"]\n","inv_vocab = checkpoint[\"inv_vocab\"]\n","\n","# Move tensors to device\n","X_padded = checkpoint[\"X_padded\"].to(device)  # PyTorch does not run natively on TPU, hence using T4 GPU\n","y_tensor = checkpoint[\"y_tensor\"].to(device)\n","\n","# DataFrame cannot move to device; it stays on CPU\n","data = checkpoint[\"data\"]\n","\n","print(data[\"moves\"].head())\n","\n","# --------------------------------\n","\n","# 5. Status\n","print(\"\\nLoaded checkpoint successfully.\\n\")\n","print(\"X_padded shape:\", X_padded.shape)\n","print(\"y_tensor shape:\", y_tensor.shape)\n","print(\"Example vocab size:\", len(vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxgllwNtp2eh","executionInfo":{"status":"ok","timestamp":1763146061704,"user_tz":-330,"elapsed":37690,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"c9170faf-5a1c-48c9-e7c7-87fb770dc0c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Using device: cpu \n","\n","0    e4 d5 Nf3 dxe4 Ne5 Nf6 d4 exd3 Bxd3 e6 Nc3 Bd6...\n","1    b4 e5 Bb2 d6 c3 Bf5 d3 Nf6 e4 Bg6 Be2 Be7 Nf3 ...\n","2    e4 d5 exd5 Qxd5 Nc3 Qa5 Nf3 Nf6 d4 Bg4 Bd2 Nc6...\n","3    e4 e5 Nf3 Nf6 Nc3 d6 Bc4 Be6 Qe2 Nbd7 d4 Bxc4 ...\n","4    d4 e6 c4 c6 Nc3 d5 cxd5 cxd5 e4 Nc6 e5 Qb6 Nge...\n","Name: moves, dtype: object\n","\n","Loaded checkpoint successfully.\n","\n","X_padded shape: torch.Size([658379, 292])\n","y_tensor shape: torch.Size([658379])\n","Example vocab size: 3672\n"]}]},{"cell_type":"code","source":["# Push changes to GitHub\n","\n","!cp /content/drive/MyDrive/ML_Sem3_Project/BaselineLSTM.ipynb /content/ML_Project_2025/\n","\n","!git add BaselineLSTM.ipynb\n","!git commit -m \"Added Notebook\"\n","!git push"],"metadata":{"id":"pwyNYaf7sT63","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763147419702,"user_tz":-330,"elapsed":1959,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"e324e86d-fa0a-412f-84ce-adec4662a02a"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 87be668] Added Notebook\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite BaselineLSTM.ipynb (97%)\n","Enumerating objects: 5, done.\n","Counting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 699 bytes | 699.00 KiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To github.com:astroartics/ML_Project_2025.git\n","   affe2f3..87be668  main -> main\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Ihkax-6kw77K"},"execution_count":null,"outputs":[]}]}