{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOaxxEwXSfUFyvq9e4CM1WJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ARVrFO-1oZVA"},"outputs":[],"source":["# Run once\n","\n","# !ssh-keygen -t rsa -b 4096 -f /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa -N \"\" -q\n","# !cat /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa.pub"]},{"cell_type":"code","source":["# Run everytime\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!mkdir -p ~/.ssh\n","!cp /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa ~/.ssh/\n","!cp /content/drive/MyDrive/ML_Sem3_Project/.ssh/id_rsa.pub ~/.ssh/\n","!chmod 600 ~/.ssh/id_rsa\n","!ssh-keyscan github.com >> ~/.ssh/known_hosts\n","\n","import os\n","\n","repo_dir = \"/content/ML_Project_2025\"\n","\n","if not os.path.exists(repo_dir):\n","  !git clone git@github.com:astroartics/ML_Project_2025.git {repo_dir}\n","else:\n","  %cd {repo_dir}\n","  !git pull\n","\n","%cd {repo_dir}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tjoHCPQpeeo","executionInfo":{"status":"ok","timestamp":1765968795722,"user_tz":-330,"elapsed":35132,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"deab11f2-9636-4d4a-fe37-0caff1794c80"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","# github.com:22 SSH-2.0-1e748d5\n","# github.com:22 SSH-2.0-1e748d5\n","# github.com:22 SSH-2.0-1e748d5\n","# github.com:22 SSH-2.0-1e748d5\n","# github.com:22 SSH-2.0-1e748d5\n","Cloning into '/content/ML_Project_2025'...\n","remote: Enumerating objects: 170, done.\u001b[K\n","remote: Counting objects: 100% (170/170), done.\u001b[K\n","remote: Compressing objects: 100% (117/117), done.\u001b[K\n","remote: Total 170 (delta 90), reused 121 (delta 41), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (170/170), 1.57 MiB | 5.35 MiB/s, done.\n","Resolving deltas: 100% (90/90), done.\n","/content/ML_Project_2025\n"]}]},{"cell_type":"code","source":["\n","# Run everytime\n","\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"\\nUsing device:\", device, \"\\n\")\n","\n","checkpoint_path = \"/content/drive/MyDrive/ML_Sem3_Project/preprocessed_data.pt\"\n","checkpoint = torch.load(\n","    checkpoint_path,\n","    map_location = device,  # ensures safe loading on CPU/GPU\n","    weights_only = False\n",")\n","\n","# --------------------------------\n","\n","# 4. Extract Variables\n","vocab = checkpoint[\"vocab\"]\n","inv_vocab = checkpoint[\"inv_vocab\"]\n","\n","# Move tensors to device\n","X_padded = checkpoint[\"X_padded\"].to(device)  # PyTorch does not run natively on TPU, hence using T4 GPU\n","y_tensor = checkpoint[\"y_tensor\"].to(device)\n","\n","# DataFrame cannot move to device; it stays on CPU\n","data = checkpoint[\"data\"]\n","\n","print(data[\"moves\"].head())\n","\n","# --------------------------------\n","\n","# 5. Status\n","print(\"\\nLoaded checkpoint successfully.\\n\")\n","print(\"X_padded shape:\", X_padded.shape)\n","print(\"y_tensor shape:\", y_tensor.shape)\n","print(\"Example vocab size:\", len(vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxgllwNtp2eh","executionInfo":{"status":"ok","timestamp":1765968827382,"user_tz":-330,"elapsed":27365,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"b93705e8-8ef6-4699-bbbc-b9c6c7477dd7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Using device: cuda \n","\n","0    e4 d5 Nf3 dxe4 Ne5 Nf6 d4 exd3 Bxd3 e6 Nc3 Bd6...\n","1    b4 e5 Bb2 d6 c3 Bf5 d3 Nf6 e4 Bg6 Be2 Be7 Nf3 ...\n","2    e4 d5 exd5 Qxd5 Nc3 Qa5 Nf3 Nf6 d4 Bg4 Bd2 Nc6...\n","3    e4 e5 Nf3 Nf6 Nc3 d6 Bc4 Be6 Qe2 Nbd7 d4 Bxc4 ...\n","4    d4 e6 c4 c6 Nc3 d5 cxd5 cxd5 e4 Nc6 e5 Qb6 Nge...\n","Name: moves, dtype: object\n","\n","Loaded checkpoint successfully.\n","\n","X_padded shape: torch.Size([658379, 292])\n","y_tensor shape: torch.Size([658379])\n","Example vocab size: 3672\n"]}]},{"cell_type":"code","source":["# Push changes to GitHub\n","\n","!git config --global user.email \"joshisanjanana114@gmail.com\"\n","!git config --global user.name \"Sanjana\"\n","\n","!cp /content/drive/MyDrive/ML_Sem3_Project/BaselineLSTM.ipynb /content/ML_Project_2025/\n","\n","!git add BaselineLSTM.ipynb\n","!git commit -m \"Added Notebook\"\n","!git push"],"metadata":{"id":"pwyNYaf7sT63","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765956438642,"user_tz":-330,"elapsed":2546,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"471e3cb8-8687-4c51-b946-36f03b5c96f3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[main a4be07e] Added Notebook\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite BaselineLSTM.ipynb (99%)\n","Enumerating objects: 5, done.\n","Counting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 2.51 KiB | 2.51 MiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To github.com:astroartics/ML_Project_2025.git\n","   5b531a4..a4be07e  main -> main\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qAjEDi-U1BOl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train/test split\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_padded,\n","    y_tensor,\n","    test_size = 0.2,  # 80-20 split\n","    random_state = 42,\n","    shuffle=True\n",")\n","\n","X_train.shape, X_test.shape\n"],"metadata":{"id":"Ihkax-6kw77K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765955249912,"user_tz":-330,"elapsed":2680,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"28ffb512-e4e4-4ed2-d900-d8511434aa26"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([526703, 292]), torch.Size([131676, 292]))"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# PyTorch Datasets and DataLoaders\n","\n","# Why these are needed:\n","'''\n","1) Data cannot be fed to the model directly, because the number of integers is huge.\n","2) It must be given to the model in batches.\n","3) A DataLoader iterates over these batches.\n","4) DataLoader handles batching, shuffling, and feeding the model (if batch size = 64, then taking 64 sequences for X and 64 labels for y)\n","5) DataLoader also uses multiple workers to load batches faster.\n","6) Dataset allows Python to treat the data like a list (shuffling indices, slicing samples, fetching mini-batches automatically)\n","7) Dataset is a wrapper that tells PyTorch \"How to get the ith sample.\"\n","8) Dataset: Defines how to access each sample\n","   DataLoader: Defines how to group examples into batches efficiently during training\n","'''\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","# X and y are not converted to a new format, they are just wrapped and become accessible through the Dataset interface\n","# For example, before Dataset, we manually index\n","# sample_X = X_train[100]\n","# sample_y = y_train[100]\n","# but, after Dataset, DataLoader can automatically fetch train_ds[100] -> returns (X_train[100], y_train[100])\n","class ChessDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    # Returns one sample to the DataLoader when requested: DataLoader needs data to be wrapped in a Dataset to\n","    # access it one by one randomly to form batches.\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","# DataLoaders\n","\n","batch_size = 64\n","\n","train_dataset = ChessDataset(X_train, y_train)\n","test_dataset  = ChessDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n","test_loader  = DataLoader(test_dataset, batch_size = batch_size)\n"],"metadata":{"id":"4I9UOiPA1Nc9","executionInfo":{"status":"ok","timestamp":1765955329573,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"G0FplOMM25dZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# Defining the Baseline LSTM model\n","\n","class BaselineLSTM(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_layers=1, padding_idx=0):\n","        super().__init__()\n","        # Embedding: converts token IDs -> dense vectors\n","        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim, padding_idx=padding_idx)\n","        # LSTM: processes sequence of embeddings\n","        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n","        # Final linear layer to produce logits for each vocabulary token\n","        self.fc = nn.Linear(hidden_dim, vocab_size)\n","\n","    def forward(self, x):\n","        # x: LongTensor of shape (batch_size, seq_len)\n","        emb = self.embedding(x)                     # -> (batch_size, seq_len, embed_dim)\n","        outputs, (h_n, c_n) = self.lstm(emb)        # outputs -> (batch_size, seq_len, hidden_dim)\n","                                                   # h_n -> (num_layers, batch_size, hidden_dim)\n","        last_hidden = outputs[:, -1, :]             # take output at last time-step -> (batch_size, hidden_dim)\n","        logits = self.fc(last_hidden)               # -> (batch_size, vocab_size)\n","        return logits\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","vocab_size = len(vocab)        # vocab from your preprocessing (includes PAD and UNK)\n","model = BaselineLSTM(vocab_size=vocab_size, embed_dim=128, hidden_dim=256, num_layers=1, padding_idx=vocab['<PAD>']).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss(ignore_index=vocab['<PAD>'])   # ignore pad index if used in targets (usually not)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","# Training loop\n","num_epochs = 10\n","model.train()\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    for X_batch, y_batch in train_loader:\n","        # Move to device\n","        X_batch = X_batch.to(device)                   # (batch_size, seq_len), dtype=torch.long\n","        y_batch = y_batch.to(device)                   # (batch_size,), dtype=torch.long (class indices)\n","\n","        optimizer.zero_grad()\n","\n","        logits = model(X_batch)                        # (batch_size, vocab_size)\n","        loss = criterion(logits, y_batch)              # CrossEntropy expects (N, C) and targets (N,)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * X_batch.size(0)    # sum-of-losses for averaging later\n","\n","    avg_loss = total_loss / len(train_loader.dataset)\n","    print(f\"Epoch {epoch+1}/{num_epochs}  Train loss: {avg_loss:.4f}\")\n","\n","# Predicting / decoding one example\n","model.eval()\n","with torch.no_grad():\n","    sample_X = X_test[0].unsqueeze(0).to(device)      # shape (1, seq_len)\n","    logits = model(sample_X)                          # (1, vocab_size)\n","    pred_id = logits.argmax(dim=-1).item()            # integer token id\n","    pred_move = inv_vocab[pred_id]                    # decode to SAN using your inv_vocab\n","    print(\"Predicted token id:\", pred_id, \"Predicted SAN:\", pred_move)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"C66lA_5N2QoL","executionInfo":{"status":"error","timestamp":1765968749535,"user_tz":-330,"elapsed":5576,"user":{"displayName":"Sanjana","userId":"03983290958884448997"}},"outputId":"963dfeea-9c2e-48eb-a090-67112ec2dfbf"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'vocab' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-443572127.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# vocab from your preprocessing (includes PAD and UNK)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaselineLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<PAD>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NrCu2ru9HUPV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"S9EjT8X0SQBO"},"execution_count":null,"outputs":[]}]}